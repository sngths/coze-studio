# Server
LISTEN_ADDR=":8888"
LOG_LEVEL="debug"
MAX_REQUEST_BODY_SIZE=1073741824
SERVER_HOST="http://coze.zczy.ai"
USE_SSL="0"
SSL_CERT_FILE=""
SSL_KEY_FILE=""
WEB_LISTEN_ADDR="0.0.0.0:8888" # To enable remote access, use 0.0.0.0:8888.

# MySQL
MYSQL_ROOT_PASSWORD=root
MYSQL_DATABASE=opencoze
MYSQL_USER=coze
MYSQL_PASSWORD=coze123
MYSQL_HOST=mysql
MYSQL_PORT=3306
MYSQL_DSN="coze:coze123@tcp(mysql:3306)/opencoze?charset=utf8mb4&parseTime=True"
ATLAS_URL="mysql://coze:coze123@mysql:3306/opencoze?charset=utf8mb4&parseTime=True"
MYSQL_MAX_IDLE_CONNS=10
MYSQL_MAX_OPEN_CONNS=100
MYSQL_CONN_MAX_LIFETIME=3600      # seconds
MYSQL_CONN_MAX_IDLE_TIME=600      # seconds

# Redis
REDIS_AOF_ENABLED=no
REDIS_IO_THREADS=4
ALLOW_EMPTY_PASSWORD=yes
REDIS_ADDR="redis:6379"
REDIS_PASSWORD=""

# This Upload component used in Agent / workflow File/Image With LLM  , support the component of imagex / storage
# default: storage, use the settings of storage component
# if imagex, you must finish the configuration of <VolcEngine ImageX>
FILE_UPLOAD_COMPONENT_TYPE="storage"

# VolcEngine ImageX
VE_IMAGEX_AK=""
VE_IMAGEX_SK=""
VE_IMAGEX_SERVER_ID=""
VE_IMAGEX_DOMAIN=""
VE_IMAGEX_TEMPLATE=""
VE_IMAGEX_UPLOAD_HOST="https://imagex.volcengineapi.com"

# Storage component
STORAGE_TYPE="minio" # minio / tos / s3
STORAGE_UPLOAD_HTTP_SCHEME="http" # http / https. If coze studio website is https, you must set it to https
STORAGE_BUCKET="opencoze"
# MiniIO
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin123
MINIO_DEFAULT_BUCKETS=milvus
MINIO_AK=$MINIO_ROOT_USER
MINIO_SK=$MINIO_ROOT_PASSWORD
MINIO_ENDPOINT="minio:9000"
MINIO_API_HOST="http://minio:9000"
MINIO_USE_SSL=false

# TOS
TOS_ACCESS_KEY=
TOS_SECRET_KEY=
TOS_ENDPOINT=https://tos-cn-beijing.volces.com
TOS_REGION=cn-beijing

# S3
S3_ACCESS_KEY=
S3_SECRET_KEY=
S3_ENDPOINT=
S3_BUCKET_ENDPOINT=
S3_REGION=

# Elasticsearch
ES_ADDR="http://elasticsearch:9200"
ES_VERSION="v8"
ES_USERNAME=""
ES_PASSWORD=""
ES_NUMBER_OF_SHARDS="1"
ES_NUMBER_OF_REPLICAS="1"

# Backend Event Bus
COZE_MQ_TYPE="nsq" # nsq / kafka / rmq / pulsar / nats
MQ_NAME_SERVER="nsqd:4150"
# RocketMQ
RMQ_ACCESS_KEY=""
RMQ_SECRET_KEY=""
# Pulsar
# Use Pulsar as backend eventbus, MQ_NAME_SERVER example is: "pulsar:6650"
# Fill PULSAR_JWT_TOKEN for JWT auth, leave empty for no auth
PULSAR_SERVICE_URL="pulsar://pulsar-service:6650"
PULSAR_JWT_TOKEN=""
# NATS
# Use NATS as backend eventbus with JetStream support
# Set COZE_MQ_TYPE="nats" and MQ_NAME_SERVER="nats:4222" to enable NATS
# NATS_SERVER_URL: NATS server connection URL, supports nats:// and tls:// protocols
# For cluster setup, use comma-separated URLs: "nats://nats1:4222,nats://nats2:4222"
# For TLS connection: "tls://nats:4222"
NATS_SERVER_URL="nats://nats:4222"
# NATS_JWT_TOKEN: JWT token for NATS authentication (leave empty for no auth)
NATS_JWT_TOKEN=""
# NATS_NKEY_SEED: Path to NATS seed file for NKey authentication (optional)
NATS_NKEY_SEED=""
# NATS_USERNAME: Username for NATS authentication (optional)
NATS_USERNAME=""
# NATS_PASSWORD: Password for NATS authentication (optional)
NATS_PASSWORD=""
# NATS_TOKEN: Token for NATS authentication (optional)
NATS_TOKEN=""
# NATS_STREAM_REPLICAS: Number of replicas for JetStream streams (default: 1)
NATS_STREAM_REPLICAS="1"
# NATS_USE_JETSTREAM: Enable JetStream mode for message persistence and reliability (default: false)
NATS_USE_JETSTREAM="true"

# Settings for VectorStore
# VectorStore type: milvus / vikingdb / oceanbase
# If you want to use vikingdb, you need to set up the vikingdb configuration.
VECTOR_STORE_TYPE="milvus"
# milvus vector store
MILVUS_ADDR="milvus:19530"
MILVUS_USER=""
MILVUS_PASSWORD=""
MILVUS_TOKEN=""
# vikingdb vector store for Volcengine
VIKING_DB_HOST=""
VIKING_DB_REGION=""
VIKING_DB_AK=""
VIKING_DB_SK=""
VIKING_DB_SCHEME=""
VIKING_DB_MODEL_NAME="" # if vikingdb model name is not set, you need to set Embedding settings

# oceanbase vector store
OCEANBASE_HOST="127.0.0.1"
OCEANBASE_PORT=2881
OCEANBASE_USER="root@test"
OCEANBASE_PASSWORD="coze123"
OCEANBASE_DATABASE="test"

# Settings for Embedding
# The Embedding model relied on by knowledge base vectorization does not need to be configured
# if the vector database comes with built-in Embedding functionality (such as VikingDB). Currently,
# Coze Studio supports four access methods: openai, ark, ollama, and custom http. Users can simply choose one of them when using
# embedding type: ark / openai / ollama / gemini / http
EMBEDDING_TYPE="ark"
EMBEDDING_MAX_BATCH_SIZE=100

# ark embedding by volcengine / byteplus
ARK_EMBEDDING_BASE_URL="" # (string, required) Ark embedding base_url
ARK_EMBEDDING_MODEL=""    # (string, required) Ark embedding model
ARK_EMBEDDING_API_KEY=""  # (string, required) Ark embedding api_key
ARK_EMBEDDING_DIMS="2048" # (int,    required) Ark embedding dimensions
ARK_EMBEDDING_API_TYPE="" # (string, optional) Ark embedding api type, should be "text_api" / "multi_modal_api". Default "text_api".

# openai embedding
OPENAI_EMBEDDING_BASE_URL=""       # (string, required) OpenAI embedding base_url
OPENAI_EMBEDDING_MODEL=""          # (string, required) OpenAI embedding model
OPENAI_EMBEDDING_API_KEY=""        # (string, required) OpenAI embedding api_key
OPENAI_EMBEDDING_BY_AZURE=false    # (bool,   optional) OpenAI embedding by_azure
OPENAI_EMBEDDING_API_VERSION=""    # (string, optional) OpenAI embedding azure api version
OPENAI_EMBEDDING_DIMS=1024         # (int,    required) OpenAI embedding dimensions
OPENAI_EMBEDDING_REQUEST_DIMS=1024 # (int,    optional) OpenAI embedding dimensions in requests, need to be empty if api doesn't support specifying dimensions.

# ollama embedding
OLLAMA_EMBEDDING_BASE_URL="" # (string, required) Ollama embedding base_url
OLLAMA_EMBEDDING_MODEL=""    # (string, required) Ollama embedding model
OLLAMA_EMBEDDING_DIMS=""     # (int,    required) Ollama embedding dimensions

# gemini embedding
GEMINI_EMBEDDING_BASE_URL=""                  # (string, required) Gemini embedding base_url
GEMINI_EMBEDDING_MODEL="gemini-embedding-001" # (string, required) Gemini embedding model.
GEMINI_EMBEDDING_API_KEY=""                   # (string, required) Gemini embedding api_key
GEMINI_EMBEDDING_DIMS=2048                    # (int,    required) Gemini embedding dimensions
GEMINI_EMBEDDING_BACKEND="1"                  # (string, required) Gemini embedding backend, should be "1" for BackendGeminiAPI / "2" for BackendVertexAI.
GEMINI_EMBEDDING_PROJECT=""                   # (string, optional) Gemini embedding project
GEMINI_EMBEDDING_LOCATION=""                  # (string, optional) Gemini embedding location

# http embedding
HTTP_EMBEDDING_ADDR=""   # (string, required) http embedding address
HTTP_EMBEDDING_DIMS=1024 # (string, required) http embedding dimensions

# Settings for Rerank
# If you want to use the rerank-related functions in the knowledge base feature，You need to set up the rerank configuration.
RERANK_TYPE="" # current support `vikingdb`,`rrf`,default:rrf
# vikingdb rerank
VIKINGDB_RERANK_HOST="" # optional,default:api-knowledgebase.mlp.cn-beijing.volces.com
VIKINGDB_RERANK_REGION="" # optional,default:cn-north-1
VIKINGDB_RERANK_AK="" # required
VIKINGDB_RERANK_SK="" # required
VIKINGDB_RERANK_MODEL="" # optional,default:base-multilingual-rerank,also support m3-v2-rerank

# Settings for OCR
# If you want to use the OCR-related functions in the knowledge base feature，You need to set up the OCR configuration.
# Currently, Coze Studio has built-in Volcano OCR.
# Supported OCR types: `ve`, `paddleocr`
OCR_TYPE="ve"
# ve ocr
VE_OCR_AK=""
VE_OCR_SK=""
# paddleocr ocr
PADDLEOCR_OCR_API_URL=""

# Settings for Document Parser
# Supported parser types: `builtin`, `paddleocr`
PARSER_TYPE="builtin"
# paddleocr structure
PADDLEOCR_STRUCTURE_API_URL=""

# Settings for Model
# Model for agent & workflow
# add suffix number to add different models
MODEL_PROTOCOL_0="ark"       # protocol
MODEL_OPENCOZE_ID_0="100001" # id for record
MODEL_NAME_0=""              # model name for show
MODEL_ID_0=""                # model name for connection
MODEL_API_KEY_0=""           # model api key
MODEL_BASE_URL_0=""           # model base url

# Model for knowledge nl2sql, messages2query (rewrite), image annotation, workflow knowledge recall
# add prefix to assign specific model, downgrade to default config when prefix is not configured:
# 1. nl2sql:                    NL2SQL_ (e.g. NL2SQL_BUILTIN_CM_TYPE)
# 2. messages2query:            M2Q_    (e.g. M2Q_BUILTIN_CM_TYPE)
# 3. image annotation:          IA_     (e.g. IA_BUILTIN_CM_TYPE)
# 4. workflow knowledge recall: WKR_    (e.g. WKR_BUILTIN_CM_TYPE)
# supported chat model type: openai / ark / deepseek / ollama / qwen / gemini
BUILTIN_CM_TYPE="ark"
# type openai
BUILTIN_CM_OPENAI_BASE_URL=""
BUILTIN_CM_OPENAI_API_KEY=""
BUILTIN_CM_OPENAI_BY_AZURE=false
BUILTIN_CM_OPENAI_MODEL=""

# type ark
BUILTIN_CM_ARK_API_KEY=""
BUILTIN_CM_ARK_MODEL=""
BUILTIN_CM_ARK_BASE_URL=""

# type deepseek
BUILTIN_CM_DEEPSEEK_BASE_URL=""
BUILTIN_CM_DEEPSEEK_API_KEY=""
BUILTIN_CM_DEEPSEEK_MODEL=""

# type ollama
BUILTIN_CM_OLLAMA_BASE_URL=""
BUILTIN_CM_OLLAMA_MODEL=""

# type qwen
BUILTIN_CM_QWEN_BASE_URL=""
BUILTIN_CM_QWEN_API_KEY=""
BUILTIN_CM_QWEN_MODEL=""

# type gemini
BUILTIN_CM_GEMINI_BACKEND=""
BUILTIN_CM_GEMINI_API_KEY=""
BUILTIN_CM_GEMINI_PROJECT=""
BUILTIN_CM_GEMINI_LOCATION=""
BUILTIN_CM_GEMINI_BASE_URL=""
BUILTIN_CM_GEMINI_MODEL=""


# Workflow Code Runner Configuration
# Supported code runner types: sandbox / local
# Default using local
# - sandbox: execute python code in a sandboxed env with deno + pyodide
# - local: using venv, no env isolation
CODE_RUNNER_TYPE="sandbox"
# Sandbox sub configuration
# Access restricted to specific environment variables, split with comma, e.g. "PATH,USERNAME"
CODE_RUNNER_ALLOW_ENV=""
# Read access restricted to specific paths, split with comma, e.g. "/tmp,./data"
CODE_RUNNER_ALLOW_READ=""
# Write access restricted to specific paths, split with comma, e.g. "/tmp,./data"
CODE_RUNNER_ALLOW_WRITE=""
# Subprocess execution restricted to specific commands, split with comma, e.g. "python,git"
CODE_RUNNER_ALLOW_RUN=""
# Network access restricted to specific domains/IPs, split with comma, e.g. "api.test.com,api.test.org:8080"
# The following CDN supports downloading the packages required for pyodide to run Python code. Sandbox may not work properly if removed.
CODE_RUNNER_ALLOW_NET="cdn.jsdelivr.net"
# Foreign Function Interface access to specific libraries, split with comma, e.g. "/usr/lib/libm.so"
CODE_RUNNER_ALLOW_FFI=""
# Directory for deno modules, default using pwd. e.g. "/tmp/path/node_modules"
CODE_RUNNER_NODE_MODULES_DIR=""
# Code execution timeout, default 60 seconds. e.g. "2.56"
CODE_RUNNER_TIMEOUT_SECONDS=""
# Code execution memory limit, default 100MB. e.g. "256"
CODE_RUNNER_MEMORY_LIMIT_MB=""

# The function of registration controller
# If you want to disable the registration feature, set DISABLE_USER_REGISTRATION to true. You can then control allowed registrations via a whitelist with ALLOW_REGISTRATION_EMAIL.
DISABLE_USER_REGISTRATION="" # default "", if you want to disable, set to true
ALLOW_REGISTRATION_EMAIL=""  #  is a list of email addresses, separated by ",". Example: "11@example.com,22@example.com"

# Plugin AES secret.
# PLUGIN_AES_AUTH_SECRET is the secret of used to encrypt plugin authorization payload.
# The size of secret must be 16, 24 or 32 bytes.
PLUGIN_AES_AUTH_SECRET='^*6x3hdu2nc%-p38'
# PLUGIN_AES_STATE_SECRET is the secret of used to encrypt oauth state.
# The size of secret must be 16, 24 or 32 bytes.
PLUGIN_AES_STATE_SECRET='osj^kfhsd*(z!sno'
# PLUGIN_AES_OAUTH_TOKEN_SECRET is the secret of used to encrypt oauth refresh token and access token.
# The size of secret must be 16, 24 or 32 bytes.
PLUGIN_AES_OAUTH_TOKEN_SECRET='cn+$PJ(HhJ[5d*z9'

# Coze Saas API Configuration
COZE_SAAS_PLUGIN_ENABLED="" # default "", if you want to enable, set to true
COZE_SAAS_API_BASE_URL="https://api.coze.cn"
COZE_SAAS_API_KEY=""
